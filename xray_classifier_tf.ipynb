{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img loading and preprocessing\n",
    "\n",
    "class_names = ('NORMAL', 'PNEUMONIA')\n",
    "\n",
    "train_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "img_size = (512, 512) # to standardize input size for cnn\n",
    "\n",
    "# load normal train imgs\n",
    "for file_name in os.listdir('data/train/NORMAL'):\n",
    "    img = np.resize(cv2.imread('data/train/NORMAL/' + file_name, 0), img_size)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    train_imgs.append(img)\n",
    "    \n",
    "# Load pneumonia train imgs\n",
    "for file_name in os.listdir('data/train/PNEUMONIA'):\n",
    "    img = np.resize(cv2.imread('data/train/PNEUMONIA/' + file_name, 0), img_size)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    train_imgs.append(img)\n",
    "    \n",
    "# load normal test imgs\n",
    "for file_name in os.listdir('data/test/NORMAL'):\n",
    "    img = np.resize(cv2.imread('data/train/NORMAL/' + file_name, 0), img_size)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    test_imgs.append(img)\n",
    "    \n",
    "# Load pneumonia test imgs\n",
    "for file_name in os.listdir('data/test/PNEUMONIA'):\n",
    "    img = np.resize(cv2.imread('data/train/PNEUMONIA/' + file_name, 0), img_size)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255.0\n",
    "    test_imgs.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more preprocessing\n",
    "\n",
    "train_x = np.array(train_imgs)\n",
    "test_x = np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more preprocessing\n",
    "\n",
    "train_x = np.expand_dims(train_x, axis=3)\n",
    "test_x = np.expand_dims(test_x, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label setup\n",
    "\n",
    "from itertools import repeat\n",
    "\n",
    "train_y = []\n",
    "test_y = []\n",
    "\n",
    "train_y.extend(repeat([0, 1], 1341))\n",
    "train_y.extend(repeat([1, 0], 3875))\n",
    "\n",
    "test_y.extend(repeat([0, 1], 242))\n",
    "test_y.extend(repeat([1, 0], 398))\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 512, 512, 4)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 256, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "=================================================================\n",
      "Total params: 38,216\n",
      "Trainable params: 38,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convolutional + pooling layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(4, (3, 3), padding='same', activation='relu', input_shape=(512, 512, 1))) # extract low level, with dimensional preservation\n",
    "model.add(layers.MaxPooling2D((2, 2))) # pool by taking max over 2 x 2 matrix\n",
    "model.add(layers.MaxPooling2D((2, 2))) # pool by taking max over 2 x 2 matrix\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2))) # pool by taking max over 2 x 2 matrix\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2))) # pool by taking max over 2 x 2 matrix\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2))) # pool by taking max over 2 x 2 matrix\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='valid', activation='relu'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 512, 512, 4)       40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 256, 256, 4)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 4)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 61, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                589888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 628,234\n",
      "Trainable params: 628,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# FC layers\n",
    "\n",
    "model.add(layers.Flatten()) # Flatten 3D output from convolutions into 1D vectors\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax')) # output of size 2 vector (to classify between normal and pneumonia)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "model.compile(optimizer=optim,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 512, 512, 1)\n",
      "(5216, 2)\n",
      "(640, 512, 512, 1)\n",
      "(640, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1, 1: 0.35}\n"
     ]
    }
   ],
   "source": [
    "# balance classes with weighting\n",
    "\n",
    "weights = {\n",
    "    0: 1, \n",
    "    1: 0.35\n",
    "}\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train on 5216 samples, validate on 640 samples\n",
      "Epoch 1/15\n",
      "5216/5216 [==============================] - 219s 42ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 2/15\n",
      "5216/5216 [==============================] - 216s 41ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 3/15\n",
      "5216/5216 [==============================] - 233s 45ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 4/15\n",
      "5216/5216 [==============================] - 214s 41ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 5/15\n",
      "5216/5216 [==============================] - 238s 46ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 6/15\n",
      "5216/5216 [==============================] - 222s 42ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 7/15\n",
      "5216/5216 [==============================] - 221s 42ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 8/15\n",
      "5216/5216 [==============================] - 236s 45ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 9/15\n",
      "5216/5216 [==============================] - 231s 44ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 10/15\n",
      "5216/5216 [==============================] - 224s 43ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 11/15\n",
      "5216/5216 [==============================] - 225s 43ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 12/15\n",
      "5216/5216 [==============================] - 201s 38ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 13/15\n",
      "5216/5216 [==============================] - 203s 39ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 14/15\n",
      "5216/5216 [==============================] - 199s 38ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n",
      "Epoch 15/15\n",
      "5216/5216 [==============================] - 198s 38ms/sample - loss: 0.4641 - accuracy: 0.7429 - val_loss: 0.4457 - val_accuracy: 0.6219\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=15, validation_data=(test_x, test_y), class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\brian\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: trained_models/xray\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('trained_models/xray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 7s 11ms/sample - loss: 0.6923 - accuracy: 0.6219\n",
      "Classification accuracy with test set: 62.187498807907104%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model with test set only\n",
    "loss, accuracy = model.evaluate(test_x, test_y, verbose=1)\n",
    "print('Classification accuracy with test set: ' + str(accuracy*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
